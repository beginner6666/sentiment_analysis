{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from keras.preprocessing.text import one_hot, Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.layers import Dense, Flatten, Embedding, LSTM, SpatialDropout1D, Input, Bidirectional,Dropout, Activation, GRU\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "train_data = pd.read_csv('Train_DataSet.csv')\n",
    "train_label = pd.read_csv('Train_DataSet_Label.csv')\n",
    "train = pd.merge(train_data, train_label, how='left', on='id')\n",
    "train = train[(train.label.notnull()) & (train.content.notnull())]\n",
    "test = pd.read_csv('Test_DataSet.csv')\n",
    "\n",
    "train['title'] = train['title'].fillna('')\n",
    "train['content'] = train['content'].fillna('')\n",
    "test['title'] = test['title'].fillna('')\n",
    "test['content'] = test['content'].fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stop_special sign_word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: Possible set difference at position 43\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "E:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: Possible set difference at position 45\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "E:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: Possible set difference at position 46\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "E:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:19: FutureWarning: read_table is deprecated, use read_csv instead, passing sep='\\t'.\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\User\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 1.624 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def filter(text):\n",
    "    text = re.sub(\"[A-Za-z0-9\\!\\=\\？\\%\\[\\]\\,\\（\\）\\>\\<:&lt;\\/#\\. -----\\_]\", \"\", text)\n",
    "    text = text.replace('图片', '')\n",
    "    text = text.replace('\\xa0', '') # 删除nbsp\n",
    "    # new\n",
    "    r1 =  \"\\\\【.*?】+|\\\\《.*?》+|\\\\#.*?#+|[.!/_,$&%^*()<>+\"\"'?@|:~{}#]+|[——！\\\\\\，。=？、：“”‘’￥……（）《》【】]\"\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    text = re.sub(cleanr, ' ', text)        #去除html标签\n",
    "    text = re.sub(r1,'',text)\n",
    "    text = text.strip()\n",
    "    return text\n",
    "def clean_text(data):\n",
    "    data['title'] = data['title'].apply(lambda x: filter(x))\n",
    "    data['content'] = data['content'].apply(lambda x: filter(x))\n",
    "    return data\n",
    "train = clean_text(train)\n",
    "test = clean_text(test)\n",
    "stop_words = pd.read_table('stop.txt', header=None)[0].tolist()\n",
    "import jieba\n",
    "import string\n",
    "table = str.maketrans(\"\",\"\",string.punctuation)\n",
    "def cut_text(sentence):\n",
    "    tokens = list(jieba.cut(sentence))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    return tokens\n",
    "train_title = [cut_text(sent) for sent in train.title.values]\n",
    "train_content = [cut_text(sent) for sent in train.content.values]\n",
    "test_title = [cut_text(sent) for sent in test.title.values]\n",
    "test_content = [cut_text(sent) for sent in test.content.values]\n",
    "all_doc = train_title + train_content + test_title + test_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# textCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import time\n",
    "class EpochSaver(gensim.models.callbacks.CallbackAny2Vec):\n",
    "    '''用于保存模型, 打印损失函数等等'''\n",
    "    def __init__(self, save_path):\n",
    "        self.save_path = save_path\n",
    "        self.epoch = 0\n",
    "        self.pre_loss = 0\n",
    "        self.best_loss = 999999999.9\n",
    "        self.since = time.time()\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        self.epoch += 1\n",
    "        cum_loss = model.get_latest_training_loss() # 返回的是从第一个epoch累计的\n",
    "        epoch_loss = cum_loss - self.pre_loss\n",
    "        time_taken = time.time() - self.since\n",
    "        print(\"Epoch %d, loss: %.2f, time: %dmin %ds\" % \n",
    "                    (self.epoch, epoch_loss, time_taken//60, time_taken%60))\n",
    "        if self.best_loss > epoch_loss:\n",
    "            self.best_loss = epoch_loss\n",
    "            print(\"Better model. Best loss: %.2f\" % self.best_loss)\n",
    "            model.save(self.save_path)\n",
    "            print(\"Model %s save done!\" % self.save_path)\n",
    "\n",
    "        self.pre_loss = cum_loss\n",
    "        self.since = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build vocab: 0min 15s\n",
      "Epoch 1, loss: 4106491.25, time: 0min 12s\n",
      "Better model. Best loss: 4106491.25\n",
      "Model ./final_word2vec_model save done!\n",
      "Epoch 2, loss: 2704354.75, time: 0min 12s\n",
      "Better model. Best loss: 2704354.75\n",
      "Model ./final_word2vec_model save done!\n",
      "Epoch 3, loss: 2281141.00, time: 0min 12s\n",
      "Better model. Best loss: 2281141.00\n",
      "Model ./final_word2vec_model save done!\n",
      "Epoch 4, loss: 1962566.00, time: 0min 13s\n",
      "Better model. Best loss: 1962566.00\n",
      "Model ./final_word2vec_model save done!\n",
      "Epoch 5, loss: 1864187.00, time: 0min 12s\n",
      "Better model. Best loss: 1864187.00\n",
      "Model ./final_word2vec_model save done!\n",
      "Time to train: 1min 31s\n",
      "32058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                        | 0/32058 [00:00<?, ?it/s]E:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:25: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 32058/32058 [00:00<00:00, 68942.16it/s]\n"
     ]
    }
   ],
   "source": [
    "model_word2vec = gensim.models.Word2Vec(min_count=1, \n",
    "                                        window=5, \n",
    "                                        size=256,\n",
    "                                        workers=4,\n",
    "                                        batch_words=1000)\n",
    "since = time.time()\n",
    "model_word2vec.build_vocab(all_doc, progress_per=2000)\n",
    "time_elapsed = time.time() - since\n",
    "print('Time to build vocab: {:.0f}min {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "since = time.time()\n",
    "model_word2vec.train(all_doc, total_examples=model_word2vec.corpus_count, \n",
    "                        epochs=5, compute_loss=True, report_delay=60*10,\n",
    "                        callbacks=[EpochSaver('./final_word2vec_model')])\n",
    "time_elapsed = time.time() - since\n",
    "print('Time to train: {:.0f}min {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "#统计长度\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train_title + test_title)\n",
    "# 转化成词向量矩阵，利用新的word2vec模型\n",
    "vocab_size = len(tokenizer.word_index)\n",
    "print(vocab_size)\n",
    "error_count=0\n",
    "embedding_matrix = np.zeros((vocab_size + 1, 256))\n",
    "for word, i in tqdm(tokenizer.word_index.items()):\n",
    "    if word in model_word2vec:\n",
    "        embedding_matrix[i] = model_word2vec.wv[word]\n",
    "    else:\n",
    "        error_count += 1\n",
    "#句子的长度        \n",
    "sequence = tokenizer.texts_to_sequences(train_title)\n",
    "traintitle = pad_sequences(sequence, maxlen=30)\n",
    "sequence = tokenizer.texts_to_sequences(test_title)\n",
    "testtitle = pad_sequences(sequence, maxlen=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 30, 256)      8207104     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 28, 128)      98432       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 27, 128)      131200      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 26, 128)      163968      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 128)          0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 128)          0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_3 (GlobalM (None, 128)          0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 384)          0           global_max_pooling1d_1[0][0]     \n",
      "                                                                 global_max_pooling1d_2[0][0]     \n",
      "                                                                 global_max_pooling1d_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 3)            1155        concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 8,601,859\n",
      "Trainable params: 8,601,859\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import Input, Model\n",
    "from keras.layers import Embedding, Dense, Conv1D, GlobalMaxPooling1D, Concatenate, Dropout\n",
    "class TextCNN(object):\n",
    "    def __init__(self, maxlen, max_features, embedding_dims,\n",
    "                 class_num=1,\n",
    "                 last_activation='sigmoid'):\n",
    "        self.maxlen = maxlen\n",
    "        self.max_features = max_features\n",
    "        self.embedding_dims = embedding_dims\n",
    "        self.class_num = class_num\n",
    "        self.last_activation = last_activation\n",
    "\n",
    "    def get_model(self):\n",
    "        input = Input((self.maxlen,))\n",
    "\n",
    "        # Embedding part can try multichannel as same as origin paper\n",
    "        embedding = Embedding(self.max_features, self.embedding_dims, input_length=self.maxlen,\n",
    "                              weights=[embedding_matrix])(input)\n",
    "        convs = []\n",
    "        for kernel_size in [3, 4, 5]:\n",
    "            c = Conv1D(128, kernel_size, activation='relu')(embedding)\n",
    "            c = GlobalMaxPooling1D()(c)\n",
    "            convs.append(c)\n",
    "        x = Concatenate()(convs)\n",
    "\n",
    "        output = Dense(self.class_num, activation=self.last_activation)(x)\n",
    "        model = Model(inputs=input, outputs=output)\n",
    "        return model\n",
    "    \n",
    "model = TextCNN(maxlen=30, max_features=len(tokenizer.word_index) + 1,\n",
    "                    embedding_dims=256, class_num=3, last_activation='softmax').get_model()\n",
    "model.compile('adam', 'categorical_crossentropy', metrics=['accuracy',metric_F1score])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5812/5812 [==============================] - ETA: 1:45 - loss: 1.2944 - acc: 0.4062 - metric_F1score: 0.37 - ETA: 57s - loss: 1.5677 - acc: 0.3984 - metric_F1score: 0.3862 - ETA: 41s - loss: 1.3996 - acc: 0.4219 - metric_F1score: 0.407 - ETA: 33s - loss: 1.2955 - acc: 0.4668 - metric_F1score: 0.449 - ETA: 28s - loss: 1.2234 - acc: 0.5078 - metric_F1score: 0.487 - ETA: 24s - loss: 1.1924 - acc: 0.5247 - metric_F1score: 0.504 - ETA: 22s - loss: 1.1496 - acc: 0.5480 - metric_F1score: 0.528 - ETA: 20s - loss: 1.1062 - acc: 0.5684 - metric_F1score: 0.550 - ETA: 18s - loss: 1.0892 - acc: 0.5833 - metric_F1score: 0.565 - ETA: 17s - loss: 1.0917 - acc: 0.5914 - metric_F1score: 0.574 - ETA: 16s - loss: 1.0853 - acc: 0.5973 - metric_F1score: 0.580 - ETA: 15s - loss: 1.0731 - acc: 0.6009 - metric_F1score: 0.583 - ETA: 14s - loss: 1.0577 - acc: 0.6094 - metric_F1score: 0.593 - ETA: 13s - loss: 1.0497 - acc: 0.6116 - metric_F1score: 0.595 - ETA: 12s - loss: 1.0290 - acc: 0.6177 - metric_F1score: 0.601 - ETA: 11s - loss: 1.0158 - acc: 0.6221 - metric_F1score: 0.606 - ETA: 11s - loss: 1.0053 - acc: 0.6255 - metric_F1score: 0.608 - ETA: 10s - loss: 0.9966 - acc: 0.6302 - metric_F1score: 0.613 - ETA: 10s - loss: 0.9948 - acc: 0.6324 - metric_F1score: 0.616 - ETA: 9s - loss: 0.9804 - acc: 0.6375 - metric_F1score: 0.622 - ETA: 9s - loss: 0.9793 - acc: 0.6399 - metric_F1score: 0.62 - ETA: 8s - loss: 0.9702 - acc: 0.6424 - metric_F1score: 0.62 - ETA: 8s - loss: 0.9678 - acc: 0.6430 - metric_F1score: 0.62 - ETA: 7s - loss: 0.9517 - acc: 0.6478 - metric_F1score: 0.63 - ETA: 7s - loss: 0.9426 - acc: 0.6475 - metric_F1score: 0.63 - ETA: 6s - loss: 0.9310 - acc: 0.6517 - metric_F1score: 0.63 - ETA: 6s - loss: 0.9198 - acc: 0.6548 - metric_F1score: 0.64 - ETA: 6s - loss: 0.9126 - acc: 0.6582 - metric_F1score: 0.64 - ETA: 5s - loss: 0.9039 - acc: 0.6606 - metric_F1score: 0.64 - ETA: 5s - loss: 0.9003 - acc: 0.6602 - metric_F1score: 0.64 - ETA: 4s - loss: 0.8987 - acc: 0.6610 - metric_F1score: 0.64 - ETA: 4s - loss: 0.8917 - acc: 0.6631 - metric_F1score: 0.64 - ETA: 4s - loss: 0.8886 - acc: 0.6655 - metric_F1score: 0.65 - ETA: 3s - loss: 0.8837 - acc: 0.6673 - metric_F1score: 0.65 - ETA: 3s - loss: 0.8800 - acc: 0.6681 - metric_F1score: 0.65 - ETA: 3s - loss: 0.8705 - acc: 0.6712 - metric_F1score: 0.65 - ETA: 2s - loss: 0.8652 - acc: 0.6738 - metric_F1score: 0.66 - ETA: 2s - loss: 0.8584 - acc: 0.6750 - metric_F1score: 0.66 - ETA: 2s - loss: 0.8557 - acc: 0.6751 - metric_F1score: 0.66 - ETA: 1s - loss: 0.8552 - acc: 0.6740 - metric_F1score: 0.66 - ETA: 1s - loss: 0.8491 - acc: 0.6759 - metric_F1score: 0.66 - ETA: 1s - loss: 0.8454 - acc: 0.6762 - metric_F1score: 0.66 - ETA: 0s - loss: 0.8444 - acc: 0.6766 - metric_F1score: 0.66 - ETA: 0s - loss: 0.8414 - acc: 0.6790 - metric_F1score: 0.66 - ETA: 0s - loss: 0.8384 - acc: 0.6804 - metric_F1score: 0.66 - 15s 3ms/step - loss: 0.8362 - acc: 0.6812 - metric_F1score: 0.6694\n",
      "Epoch 2/10\n",
      "5812/5812 [==============================] - ETA: 13s - loss: 0.5082 - acc: 0.8047 - metric_F1score: 0.809 - ETA: 13s - loss: 0.4398 - acc: 0.8359 - metric_F1score: 0.835 - ETA: 12s - loss: 0.4322 - acc: 0.8359 - metric_F1score: 0.832 - ETA: 12s - loss: 0.4127 - acc: 0.8418 - metric_F1score: 0.839 - ETA: 12s - loss: 0.4009 - acc: 0.8484 - metric_F1score: 0.843 - ETA: 11s - loss: 0.4129 - acc: 0.8411 - metric_F1score: 0.837 - ETA: 11s - loss: 0.4239 - acc: 0.8315 - metric_F1score: 0.828 - ETA: 11s - loss: 0.4350 - acc: 0.8262 - metric_F1score: 0.821 - ETA: 10s - loss: 0.4260 - acc: 0.8307 - metric_F1score: 0.826 - ETA: 10s - loss: 0.4339 - acc: 0.8266 - metric_F1score: 0.824 - ETA: 10s - loss: 0.4369 - acc: 0.8246 - metric_F1score: 0.823 - ETA: 9s - loss: 0.4492 - acc: 0.8236 - metric_F1score: 0.820 - ETA: 9s - loss: 0.4438 - acc: 0.8269 - metric_F1score: 0.82 - ETA: 9s - loss: 0.4440 - acc: 0.8259 - metric_F1score: 0.82 - ETA: 8s - loss: 0.4405 - acc: 0.8276 - metric_F1score: 0.82 - ETA: 8s - loss: 0.4331 - acc: 0.8311 - metric_F1score: 0.82 - ETA: 8s - loss: 0.4325 - acc: 0.8304 - metric_F1score: 0.82 - ETA: 8s - loss: 0.4296 - acc: 0.8316 - metric_F1score: 0.82 - ETA: 7s - loss: 0.4279 - acc: 0.8322 - metric_F1score: 0.82 - ETA: 7s - loss: 0.4294 - acc: 0.8324 - metric_F1score: 0.82 - ETA: 7s - loss: 0.4282 - acc: 0.8341 - metric_F1score: 0.82 - ETA: 6s - loss: 0.4282 - acc: 0.8324 - metric_F1score: 0.82 - ETA: 6s - loss: 0.4334 - acc: 0.8325 - metric_F1score: 0.82 - ETA: 6s - loss: 0.4316 - acc: 0.8330 - metric_F1score: 0.82 - ETA: 6s - loss: 0.4297 - acc: 0.8334 - metric_F1score: 0.82 - ETA: 5s - loss: 0.4294 - acc: 0.8344 - metric_F1score: 0.82 - ETA: 5s - loss: 0.4297 - acc: 0.8351 - metric_F1score: 0.82 - ETA: 5s - loss: 0.4311 - acc: 0.8334 - metric_F1score: 0.82 - ETA: 4s - loss: 0.4288 - acc: 0.8351 - metric_F1score: 0.82 - ETA: 4s - loss: 0.4300 - acc: 0.8352 - metric_F1score: 0.83 - ETA: 4s - loss: 0.4301 - acc: 0.8354 - metric_F1score: 0.82 - ETA: 3s - loss: 0.4312 - acc: 0.8352 - metric_F1score: 0.82 - ETA: 3s - loss: 0.4310 - acc: 0.8340 - metric_F1score: 0.82 - ETA: 3s - loss: 0.4308 - acc: 0.8350 - metric_F1score: 0.83 - ETA: 3s - loss: 0.4295 - acc: 0.8364 - metric_F1score: 0.83 - ETA: 2s - loss: 0.4270 - acc: 0.8377 - metric_F1score: 0.83 - ETA: 2s - loss: 0.4261 - acc: 0.8372 - metric_F1score: 0.83 - ETA: 2s - loss: 0.4250 - acc: 0.8372 - metric_F1score: 0.83 - ETA: 1s - loss: 0.4252 - acc: 0.8369 - metric_F1score: 0.83 - ETA: 1s - loss: 0.4246 - acc: 0.8363 - metric_F1score: 0.83 - ETA: 1s - loss: 0.4255 - acc: 0.8367 - metric_F1score: 0.83 - ETA: 0s - loss: 0.4239 - acc: 0.8378 - metric_F1score: 0.83 - ETA: 0s - loss: 0.4241 - acc: 0.8378 - metric_F1score: 0.83 - ETA: 0s - loss: 0.4249 - acc: 0.8379 - metric_F1score: 0.83 - ETA: 0s - loss: 0.4244 - acc: 0.8385 - metric_F1score: 0.83 - 13s 2ms/step - loss: 0.4238 - acc: 0.8391 - metric_F1score: 0.8347\n",
      "Epoch 3/10\n",
      "5812/5812 [==============================] - ETA: 12s - loss: 0.2391 - acc: 0.9375 - metric_F1score: 0.929 - ETA: 11s - loss: 0.2806 - acc: 0.9102 - metric_F1score: 0.904 - ETA: 11s - loss: 0.2628 - acc: 0.9193 - metric_F1score: 0.916 - ETA: 11s - loss: 0.2455 - acc: 0.9316 - metric_F1score: 0.927 - ETA: 11s - loss: 0.2419 - acc: 0.9359 - metric_F1score: 0.932 - ETA: 10s - loss: 0.2493 - acc: 0.9323 - metric_F1score: 0.930 - ETA: 10s - loss: 0.2627 - acc: 0.9230 - metric_F1score: 0.920 - ETA: 10s - loss: 0.2566 - acc: 0.9258 - metric_F1score: 0.924 - ETA: 10s - loss: 0.2645 - acc: 0.9219 - metric_F1score: 0.921 - ETA: 9s - loss: 0.2616 - acc: 0.9250 - metric_F1score: 0.924 - ETA: 9s - loss: 0.2648 - acc: 0.9240 - metric_F1score: 0.92 - ETA: 9s - loss: 0.2603 - acc: 0.9271 - metric_F1score: 0.92 - ETA: 9s - loss: 0.2611 - acc: 0.9261 - metric_F1score: 0.92 - ETA: 8s - loss: 0.2601 - acc: 0.9263 - metric_F1score: 0.92 - ETA: 8s - loss: 0.2582 - acc: 0.9271 - metric_F1score: 0.92 - ETA: 8s - loss: 0.2581 - acc: 0.9272 - metric_F1score: 0.92 - ETA: 8s - loss: 0.2578 - acc: 0.9265 - metric_F1score: 0.92 - ETA: 7s - loss: 0.2575 - acc: 0.9271 - metric_F1score: 0.92 - ETA: 7s - loss: 0.2557 - acc: 0.9260 - metric_F1score: 0.92 - ETA: 7s - loss: 0.2586 - acc: 0.9254 - metric_F1score: 0.92 - ETA: 6s - loss: 0.2595 - acc: 0.9249 - metric_F1score: 0.92 - ETA: 6s - loss: 0.2577 - acc: 0.9247 - metric_F1score: 0.92 - ETA: 6s - loss: 0.2588 - acc: 0.9232 - metric_F1score: 0.92 - ETA: 6s - loss: 0.2603 - acc: 0.9229 - metric_F1score: 0.92 - ETA: 5s - loss: 0.2588 - acc: 0.9234 - metric_F1score: 0.92 - ETA: 5s - loss: 0.2575 - acc: 0.9237 - metric_F1score: 0.92 - ETA: 5s - loss: 0.2562 - acc: 0.9236 - metric_F1score: 0.92 - ETA: 4s - loss: 0.2564 - acc: 0.9235 - metric_F1score: 0.92 - ETA: 4s - loss: 0.2575 - acc: 0.9230 - metric_F1score: 0.92 - ETA: 4s - loss: 0.2585 - acc: 0.9229 - metric_F1score: 0.92 - ETA: 4s - loss: 0.2573 - acc: 0.9236 - metric_F1score: 0.92 - ETA: 3s - loss: 0.2567 - acc: 0.9241 - metric_F1score: 0.92 - ETA: 3s - loss: 0.2584 - acc: 0.9226 - metric_F1score: 0.92 - ETA: 3s - loss: 0.2602 - acc: 0.9223 - metric_F1score: 0.92 - ETA: 2s - loss: 0.2636 - acc: 0.9194 - metric_F1score: 0.92 - ETA: 2s - loss: 0.2649 - acc: 0.9182 - metric_F1score: 0.91 - ETA: 2s - loss: 0.2654 - acc: 0.9174 - metric_F1score: 0.91 - ETA: 2s - loss: 0.2648 - acc: 0.9171 - metric_F1score: 0.91 - ETA: 1s - loss: 0.2655 - acc: 0.9173 - metric_F1score: 0.91 - ETA: 1s - loss: 0.2635 - acc: 0.9182 - metric_F1score: 0.91 - ETA: 1s - loss: 0.2635 - acc: 0.9177 - metric_F1score: 0.91 - ETA: 0s - loss: 0.2647 - acc: 0.9170 - metric_F1score: 0.91 - ETA: 0s - loss: 0.2655 - acc: 0.9166 - metric_F1score: 0.91 - ETA: 0s - loss: 0.2659 - acc: 0.9158 - metric_F1score: 0.91 - ETA: 0s - loss: 0.2652 - acc: 0.9168 - metric_F1score: 0.91 - 13s 2ms/step - loss: 0.2652 - acc: 0.9167 - metric_F1score: 0.9177\n",
      "Epoch 4/10\n",
      "5812/5812 [==============================] - ETA: 11s - loss: 0.1907 - acc: 0.9609 - metric_F1score: 0.968 - ETA: 11s - loss: 0.1957 - acc: 0.9531 - metric_F1score: 0.950 - ETA: 11s - loss: 0.2050 - acc: 0.9453 - metric_F1score: 0.944 - ETA: 11s - loss: 0.1936 - acc: 0.9492 - metric_F1score: 0.949 - ETA: 10s - loss: 0.1884 - acc: 0.9516 - metric_F1score: 0.951 - ETA: 10s - loss: 0.1861 - acc: 0.9544 - metric_F1score: 0.954 - ETA: 10s - loss: 0.1852 - acc: 0.9576 - metric_F1score: 0.956 - ETA: 10s - loss: 0.1844 - acc: 0.9600 - metric_F1score: 0.959 - ETA: 9s - loss: 0.1848 - acc: 0.9601 - metric_F1score: 0.958 - ETA: 9s - loss: 0.1831 - acc: 0.9609 - metric_F1score: 0.95 - ETA: 9s - loss: 0.1786 - acc: 0.9638 - metric_F1score: 0.96 - ETA: 9s - loss: 0.1776 - acc: 0.9642 - metric_F1score: 0.96 - ETA: 8s - loss: 0.1744 - acc: 0.9657 - metric_F1score: 0.96 - ETA: 8s - loss: 0.1735 - acc: 0.9665 - metric_F1score: 0.96 - ETA: 8s - loss: 0.1735 - acc: 0.9667 - metric_F1score: 0.96 - ETA: 8s - loss: 0.1717 - acc: 0.9673 - metric_F1score: 0.96 - ETA: 7s - loss: 0.1696 - acc: 0.9683 - metric_F1score: 0.96 - ETA: 7s - loss: 0.1700 - acc: 0.9670 - metric_F1score: 0.96 - ETA: 7s - loss: 0.1692 - acc: 0.9663 - metric_F1score: 0.96 - ETA: 6s - loss: 0.1697 - acc: 0.9656 - metric_F1score: 0.96 - ETA: 6s - loss: 0.1690 - acc: 0.9661 - metric_F1score: 0.96 - ETA: 6s - loss: 0.1672 - acc: 0.9666 - metric_F1score: 0.96 - ETA: 6s - loss: 0.1666 - acc: 0.9667 - metric_F1score: 0.96 - ETA: 5s - loss: 0.1660 - acc: 0.9665 - metric_F1score: 0.96 - ETA: 5s - loss: 0.1662 - acc: 0.9659 - metric_F1score: 0.96 - ETA: 5s - loss: 0.1667 - acc: 0.9657 - metric_F1score: 0.96 - ETA: 5s - loss: 0.1656 - acc: 0.9661 - metric_F1score: 0.96 - ETA: 4s - loss: 0.1656 - acc: 0.9657 - metric_F1score: 0.96 - ETA: 4s - loss: 0.1651 - acc: 0.9650 - metric_F1score: 0.96 - ETA: 4s - loss: 0.1668 - acc: 0.9638 - metric_F1score: 0.96 - ETA: 3s - loss: 0.1673 - acc: 0.9630 - metric_F1score: 0.96 - ETA: 3s - loss: 0.1672 - acc: 0.9634 - metric_F1score: 0.96 - ETA: 3s - loss: 0.1676 - acc: 0.9633 - metric_F1score: 0.96 - ETA: 3s - loss: 0.1676 - acc: 0.9630 - metric_F1score: 0.96 - ETA: 2s - loss: 0.1668 - acc: 0.9629 - metric_F1score: 0.96 - ETA: 2s - loss: 0.1664 - acc: 0.9629 - metric_F1score: 0.96 - ETA: 2s - loss: 0.1666 - acc: 0.9628 - metric_F1score: 0.96 - ETA: 2s - loss: 0.1671 - acc: 0.9620 - metric_F1score: 0.96 - ETA: 1s - loss: 0.1668 - acc: 0.9623 - metric_F1score: 0.96 - ETA: 1s - loss: 0.1660 - acc: 0.9629 - metric_F1score: 0.96 - ETA: 1s - loss: 0.1656 - acc: 0.9632 - metric_F1score: 0.96 - ETA: 0s - loss: 0.1649 - acc: 0.9639 - metric_F1score: 0.96 - ETA: 0s - loss: 0.1650 - acc: 0.9637 - metric_F1score: 0.96 - ETA: 0s - loss: 0.1651 - acc: 0.9636 - metric_F1score: 0.96 - ETA: 0s - loss: 0.1667 - acc: 0.9632 - metric_F1score: 0.96 - 13s 2ms/step - loss: 0.1668 - acc: 0.9628 - metric_F1score: 0.9623\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5812/5812 [==============================] - ETA: 12s - loss: 0.0983 - acc: 0.9922 - metric_F1score: 0.988 - ETA: 11s - loss: 0.1177 - acc: 0.9883 - metric_F1score: 0.980 - ETA: 11s - loss: 0.1211 - acc: 0.9870 - metric_F1score: 0.981 - ETA: 11s - loss: 0.1193 - acc: 0.9863 - metric_F1score: 0.982 - ETA: 11s - loss: 0.1159 - acc: 0.9844 - metric_F1score: 0.981 - ETA: 10s - loss: 0.1121 - acc: 0.9857 - metric_F1score: 0.981 - ETA: 10s - loss: 0.1090 - acc: 0.9844 - metric_F1score: 0.981 - ETA: 10s - loss: 0.1049 - acc: 0.9863 - metric_F1score: 0.983 - ETA: 10s - loss: 0.1059 - acc: 0.9861 - metric_F1score: 0.983 - ETA: 9s - loss: 0.1104 - acc: 0.9836 - metric_F1score: 0.981 - ETA: 9s - loss: 0.1131 - acc: 0.9801 - metric_F1score: 0.97 - ETA: 9s - loss: 0.1142 - acc: 0.9798 - metric_F1score: 0.97 - ETA: 8s - loss: 0.1140 - acc: 0.9802 - metric_F1score: 0.97 - ETA: 8s - loss: 0.1155 - acc: 0.9794 - metric_F1score: 0.97 - ETA: 8s - loss: 0.1156 - acc: 0.9797 - metric_F1score: 0.97 - ETA: 8s - loss: 0.1143 - acc: 0.9810 - metric_F1score: 0.97 - ETA: 7s - loss: 0.1126 - acc: 0.9816 - metric_F1score: 0.98 - ETA: 7s - loss: 0.1126 - acc: 0.9818 - metric_F1score: 0.98 - ETA: 7s - loss: 0.1125 - acc: 0.9815 - metric_F1score: 0.98 - ETA: 7s - loss: 0.1106 - acc: 0.9824 - metric_F1score: 0.98 - ETA: 6s - loss: 0.1099 - acc: 0.9821 - metric_F1score: 0.98 - ETA: 6s - loss: 0.1102 - acc: 0.9822 - metric_F1score: 0.98 - ETA: 6s - loss: 0.1096 - acc: 0.9823 - metric_F1score: 0.98 - ETA: 5s - loss: 0.1115 - acc: 0.9818 - metric_F1score: 0.98 - ETA: 5s - loss: 0.1115 - acc: 0.9819 - metric_F1score: 0.98 - ETA: 5s - loss: 0.1110 - acc: 0.9823 - metric_F1score: 0.98 - ETA: 5s - loss: 0.1110 - acc: 0.9818 - metric_F1score: 0.98 - ETA: 4s - loss: 0.1107 - acc: 0.9819 - metric_F1score: 0.98 - ETA: 4s - loss: 0.1107 - acc: 0.9820 - metric_F1score: 0.98 - ETA: 4s - loss: 0.1103 - acc: 0.9823 - metric_F1score: 0.98 - ETA: 4s - loss: 0.1101 - acc: 0.9824 - metric_F1score: 0.98 - ETA: 3s - loss: 0.1109 - acc: 0.9814 - metric_F1score: 0.98 - ETA: 3s - loss: 0.1106 - acc: 0.9818 - metric_F1score: 0.98 - ETA: 3s - loss: 0.1104 - acc: 0.9814 - metric_F1score: 0.98 - ETA: 2s - loss: 0.1114 - acc: 0.9806 - metric_F1score: 0.97 - ETA: 2s - loss: 0.1110 - acc: 0.9805 - metric_F1score: 0.98 - ETA: 2s - loss: 0.1117 - acc: 0.9802 - metric_F1score: 0.97 - ETA: 2s - loss: 0.1111 - acc: 0.9801 - metric_F1score: 0.97 - ETA: 1s - loss: 0.1105 - acc: 0.9804 - metric_F1score: 0.98 - ETA: 1s - loss: 0.1108 - acc: 0.9803 - metric_F1score: 0.98 - ETA: 1s - loss: 0.1118 - acc: 0.9800 - metric_F1score: 0.97 - ETA: 0s - loss: 0.1125 - acc: 0.9797 - metric_F1score: 0.97 - ETA: 0s - loss: 0.1124 - acc: 0.9798 - metric_F1score: 0.97 - ETA: 0s - loss: 0.1118 - acc: 0.9799 - metric_F1score: 0.97 - ETA: 0s - loss: 0.1118 - acc: 0.9800 - metric_F1score: 0.97 - 13s 2ms/step - loss: 0.1115 - acc: 0.9800 - metric_F1score: 0.9799\n",
      "Epoch 6/10\n",
      "5812/5812 [==============================] - ETA: 12s - loss: 0.0794 - acc: 0.9844 - metric_F1score: 0.984 - ETA: 11s - loss: 0.0650 - acc: 0.9922 - metric_F1score: 0.992 - ETA: 11s - loss: 0.0597 - acc: 0.9948 - metric_F1score: 0.994 - ETA: 11s - loss: 0.0656 - acc: 0.9922 - metric_F1score: 0.991 - ETA: 11s - loss: 0.0666 - acc: 0.9922 - metric_F1score: 0.991 - ETA: 10s - loss: 0.0703 - acc: 0.9896 - metric_F1score: 0.989 - ETA: 10s - loss: 0.0697 - acc: 0.9900 - metric_F1score: 0.990 - ETA: 10s - loss: 0.0687 - acc: 0.9912 - metric_F1score: 0.991 - ETA: 9s - loss: 0.0680 - acc: 0.9922 - metric_F1score: 0.992 - ETA: 9s - loss: 0.0672 - acc: 0.9922 - metric_F1score: 0.99 - ETA: 9s - loss: 0.0698 - acc: 0.9915 - metric_F1score: 0.99 - ETA: 9s - loss: 0.0697 - acc: 0.9915 - metric_F1score: 0.99 - ETA: 9s - loss: 0.0682 - acc: 0.9922 - metric_F1score: 0.99 - ETA: 8s - loss: 0.0682 - acc: 0.9922 - metric_F1score: 0.99 - ETA: 8s - loss: 0.0703 - acc: 0.9911 - metric_F1score: 0.99 - ETA: 8s - loss: 0.0702 - acc: 0.9907 - metric_F1score: 0.99 - ETA: 7s - loss: 0.0691 - acc: 0.9913 - metric_F1score: 0.99 - ETA: 7s - loss: 0.0689 - acc: 0.9913 - metric_F1score: 0.99 - ETA: 7s - loss: 0.0703 - acc: 0.9910 - metric_F1score: 0.99 - ETA: 7s - loss: 0.0695 - acc: 0.9914 - metric_F1score: 0.99 - ETA: 6s - loss: 0.0694 - acc: 0.9911 - metric_F1score: 0.99 - ETA: 6s - loss: 0.0696 - acc: 0.9911 - metric_F1score: 0.99 - ETA: 6s - loss: 0.0697 - acc: 0.9908 - metric_F1score: 0.99 - ETA: 5s - loss: 0.0694 - acc: 0.9906 - metric_F1score: 0.99 - ETA: 5s - loss: 0.0691 - acc: 0.9909 - metric_F1score: 0.99 - ETA: 5s - loss: 0.0688 - acc: 0.9910 - metric_F1score: 0.99 - ETA: 5s - loss: 0.0696 - acc: 0.9905 - metric_F1score: 0.99 - ETA: 4s - loss: 0.0689 - acc: 0.9908 - metric_F1score: 0.99 - ETA: 4s - loss: 0.0692 - acc: 0.9908 - metric_F1score: 0.99 - ETA: 4s - loss: 0.0695 - acc: 0.9909 - metric_F1score: 0.99 - ETA: 3s - loss: 0.0707 - acc: 0.9907 - metric_F1score: 0.99 - ETA: 3s - loss: 0.0713 - acc: 0.9905 - metric_F1score: 0.99 - ETA: 3s - loss: 0.0707 - acc: 0.9908 - metric_F1score: 0.99 - ETA: 3s - loss: 0.0712 - acc: 0.9903 - metric_F1score: 0.99 - ETA: 2s - loss: 0.0712 - acc: 0.9904 - metric_F1score: 0.99 - ETA: 2s - loss: 0.0720 - acc: 0.9900 - metric_F1score: 0.99 - ETA: 2s - loss: 0.0724 - acc: 0.9901 - metric_F1score: 0.99 - ETA: 2s - loss: 0.0733 - acc: 0.9897 - metric_F1score: 0.98 - ETA: 1s - loss: 0.0734 - acc: 0.9896 - metric_F1score: 0.98 - ETA: 1s - loss: 0.0731 - acc: 0.9896 - metric_F1score: 0.98 - ETA: 1s - loss: 0.0730 - acc: 0.9899 - metric_F1score: 0.98 - ETA: 0s - loss: 0.0724 - acc: 0.9901 - metric_F1score: 0.99 - ETA: 0s - loss: 0.0728 - acc: 0.9898 - metric_F1score: 0.98 - ETA: 0s - loss: 0.0736 - acc: 0.9893 - metric_F1score: 0.98 - ETA: 0s - loss: 0.0733 - acc: 0.9894 - metric_F1score: 0.98 - 13s 2ms/step - loss: 0.0732 - acc: 0.9895 - metric_F1score: 0.9896\n",
      "Epoch 7/10\n",
      "5812/5812 [==============================] - ETA: 12s - loss: 0.0489 - acc: 0.9922 - metric_F1score: 0.992 - ETA: 12s - loss: 0.0475 - acc: 0.9961 - metric_F1score: 0.996 - ETA: 11s - loss: 0.0418 - acc: 0.9974 - metric_F1score: 0.997 - ETA: 11s - loss: 0.0421 - acc: 0.9980 - metric_F1score: 0.998 - ETA: 11s - loss: 0.0441 - acc: 0.9969 - metric_F1score: 0.996 - ETA: 10s - loss: 0.0445 - acc: 0.9961 - metric_F1score: 0.996 - ETA: 10s - loss: 0.0432 - acc: 0.9967 - metric_F1score: 0.996 - ETA: 10s - loss: 0.0510 - acc: 0.9941 - metric_F1score: 0.994 - ETA: 10s - loss: 0.0493 - acc: 0.9948 - metric_F1score: 0.994 - ETA: 9s - loss: 0.0486 - acc: 0.9953 - metric_F1score: 0.994 - ETA: 9s - loss: 0.0522 - acc: 0.9936 - metric_F1score: 0.99 - ETA: 9s - loss: 0.0514 - acc: 0.9941 - metric_F1score: 0.99 - ETA: 8s - loss: 0.0518 - acc: 0.9940 - metric_F1score: 0.99 - ETA: 8s - loss: 0.0510 - acc: 0.9944 - metric_F1score: 0.99 - ETA: 8s - loss: 0.0532 - acc: 0.9932 - metric_F1score: 0.99 - ETA: 8s - loss: 0.0523 - acc: 0.9937 - metric_F1score: 0.99 - ETA: 7s - loss: 0.0531 - acc: 0.9936 - metric_F1score: 0.99 - ETA: 7s - loss: 0.0523 - acc: 0.9939 - metric_F1score: 0.99 - ETA: 7s - loss: 0.0527 - acc: 0.9938 - metric_F1score: 0.99 - ETA: 6s - loss: 0.0524 - acc: 0.9938 - metric_F1score: 0.99 - ETA: 6s - loss: 0.0514 - acc: 0.9940 - metric_F1score: 0.99 - ETA: 6s - loss: 0.0527 - acc: 0.9936 - metric_F1score: 0.99 - ETA: 6s - loss: 0.0519 - acc: 0.9939 - metric_F1score: 0.99 - ETA: 5s - loss: 0.0516 - acc: 0.9941 - metric_F1score: 0.99 - ETA: 5s - loss: 0.0508 - acc: 0.9944 - metric_F1score: 0.99 - ETA: 5s - loss: 0.0507 - acc: 0.9940 - metric_F1score: 0.99 - ETA: 5s - loss: 0.0504 - acc: 0.9942 - metric_F1score: 0.99 - ETA: 4s - loss: 0.0514 - acc: 0.9936 - metric_F1score: 0.99 - ETA: 4s - loss: 0.0512 - acc: 0.9938 - metric_F1score: 0.99 - ETA: 4s - loss: 0.0515 - acc: 0.9935 - metric_F1score: 0.99 - ETA: 3s - loss: 0.0514 - acc: 0.9937 - metric_F1score: 0.99 - ETA: 3s - loss: 0.0515 - acc: 0.9937 - metric_F1score: 0.99 - ETA: 3s - loss: 0.0508 - acc: 0.9938 - metric_F1score: 0.99 - ETA: 3s - loss: 0.0524 - acc: 0.9936 - metric_F1score: 0.99 - ETA: 2s - loss: 0.0521 - acc: 0.9938 - metric_F1score: 0.99 - ETA: 2s - loss: 0.0525 - acc: 0.9937 - metric_F1score: 0.99 - ETA: 2s - loss: 0.0538 - acc: 0.9928 - metric_F1score: 0.99 - ETA: 2s - loss: 0.0536 - acc: 0.9928 - metric_F1score: 0.99 - ETA: 1s - loss: 0.0533 - acc: 0.9930 - metric_F1score: 0.99 - ETA: 1s - loss: 0.0531 - acc: 0.9932 - metric_F1score: 0.99 - ETA: 1s - loss: 0.0528 - acc: 0.9933 - metric_F1score: 0.99 - ETA: 0s - loss: 0.0530 - acc: 0.9931 - metric_F1score: 0.99 - ETA: 0s - loss: 0.0545 - acc: 0.9929 - metric_F1score: 0.99 - ETA: 0s - loss: 0.0543 - acc: 0.9929 - metric_F1score: 0.99 - ETA: 0s - loss: 0.0543 - acc: 0.9931 - metric_F1score: 0.99 - 13s 2ms/step - loss: 0.0543 - acc: 0.9931 - metric_F1score: 0.9934\n",
      "Epoch 8/10\n",
      "5812/5812 [==============================] - ETA: 11s - loss: 0.0350 - acc: 1.0000 - metric_F1score: 1.000 - ETA: 11s - loss: 0.0386 - acc: 0.9961 - metric_F1score: 0.996 - ETA: 11s - loss: 0.0359 - acc: 0.9974 - metric_F1score: 0.997 - ETA: 11s - loss: 0.0365 - acc: 0.9980 - metric_F1score: 0.998 - ETA: 11s - loss: 0.0482 - acc: 0.9969 - metric_F1score: 0.996 - ETA: 10s - loss: 0.0448 - acc: 0.9961 - metric_F1score: 0.996 - ETA: 10s - loss: 0.0430 - acc: 0.9967 - metric_F1score: 0.996 - ETA: 10s - loss: 0.0430 - acc: 0.9961 - metric_F1score: 0.996 - ETA: 9s - loss: 0.0415 - acc: 0.9965 - metric_F1score: 0.996 - ETA: 9s - loss: 0.0420 - acc: 0.9961 - metric_F1score: 0.99 - ETA: 9s - loss: 0.0406 - acc: 0.9964 - metric_F1score: 0.99 - ETA: 9s - loss: 0.0410 - acc: 0.9961 - metric_F1score: 0.99 - ETA: 8s - loss: 0.0405 - acc: 0.9958 - metric_F1score: 0.99 - ETA: 8s - loss: 0.0446 - acc: 0.9944 - metric_F1score: 0.99 - ETA: 8s - loss: 0.0439 - acc: 0.9948 - metric_F1score: 0.99 - ETA: 8s - loss: 0.0440 - acc: 0.9946 - metric_F1score: 0.99 - ETA: 7s - loss: 0.0431 - acc: 0.9949 - metric_F1score: 0.99 - ETA: 7s - loss: 0.0436 - acc: 0.9939 - metric_F1score: 0.99 - ETA: 7s - loss: 0.0426 - acc: 0.9942 - metric_F1score: 0.99 - ETA: 6s - loss: 0.0421 - acc: 0.9945 - metric_F1score: 0.99 - ETA: 6s - loss: 0.0415 - acc: 0.9948 - metric_F1score: 0.99 - ETA: 6s - loss: 0.0416 - acc: 0.9943 - metric_F1score: 0.99 - ETA: 6s - loss: 0.0411 - acc: 0.9946 - metric_F1score: 0.99 - ETA: 5s - loss: 0.0404 - acc: 0.9948 - metric_F1score: 0.99 - ETA: 5s - loss: 0.0397 - acc: 0.9950 - metric_F1score: 0.99 - ETA: 5s - loss: 0.0390 - acc: 0.9952 - metric_F1score: 0.99 - ETA: 5s - loss: 0.0388 - acc: 0.9951 - metric_F1score: 0.99 - ETA: 4s - loss: 0.0399 - acc: 0.9950 - metric_F1score: 0.99 - ETA: 4s - loss: 0.0394 - acc: 0.9952 - metric_F1score: 0.99 - ETA: 4s - loss: 0.0393 - acc: 0.9953 - metric_F1score: 0.99 - ETA: 3s - loss: 0.0393 - acc: 0.9952 - metric_F1score: 0.99 - ETA: 3s - loss: 0.0390 - acc: 0.9954 - metric_F1score: 0.99 - ETA: 3s - loss: 0.0398 - acc: 0.9950 - metric_F1score: 0.99 - ETA: 3s - loss: 0.0392 - acc: 0.9952 - metric_F1score: 0.99 - ETA: 2s - loss: 0.0394 - acc: 0.9951 - metric_F1score: 0.99 - ETA: 2s - loss: 0.0399 - acc: 0.9948 - metric_F1score: 0.99 - ETA: 2s - loss: 0.0396 - acc: 0.9949 - metric_F1score: 0.99 - ETA: 2s - loss: 0.0392 - acc: 0.9951 - metric_F1score: 0.99 - ETA: 1s - loss: 0.0395 - acc: 0.9950 - metric_F1score: 0.99 - ETA: 1s - loss: 0.0391 - acc: 0.9951 - metric_F1score: 0.99 - ETA: 1s - loss: 0.0387 - acc: 0.9952 - metric_F1score: 0.99 - ETA: 0s - loss: 0.0383 - acc: 0.9953 - metric_F1score: 0.99 - ETA: 0s - loss: 0.0402 - acc: 0.9947 - metric_F1score: 0.99 - ETA: 0s - loss: 0.0408 - acc: 0.9945 - metric_F1score: 0.99 - ETA: 0s - loss: 0.0429 - acc: 0.9941 - metric_F1score: 0.99 - 13s 2ms/step - loss: 0.0429 - acc: 0.9942 - metric_F1score: 0.9941\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5812/5812 [==============================] - ETA: 11s - loss: 0.0253 - acc: 0.9922 - metric_F1score: 0.992 - ETA: 11s - loss: 0.0251 - acc: 0.9961 - metric_F1score: 0.996 - ETA: 11s - loss: 0.0258 - acc: 0.9974 - metric_F1score: 0.997 - ETA: 11s - loss: 0.0272 - acc: 0.9961 - metric_F1score: 0.997 - ETA: 10s - loss: 0.0262 - acc: 0.9969 - metric_F1score: 0.997 - ETA: 10s - loss: 0.0301 - acc: 0.9961 - metric_F1score: 0.996 - ETA: 10s - loss: 0.0305 - acc: 0.9955 - metric_F1score: 0.996 - ETA: 10s - loss: 0.0338 - acc: 0.9951 - metric_F1score: 0.995 - ETA: 9s - loss: 0.0321 - acc: 0.9957 - metric_F1score: 0.996 - ETA: 9s - loss: 0.0306 - acc: 0.9961 - metric_F1score: 0.99 - ETA: 9s - loss: 0.0304 - acc: 0.9957 - metric_F1score: 0.99 - ETA: 9s - loss: 0.0307 - acc: 0.9954 - metric_F1score: 0.99 - ETA: 8s - loss: 0.0318 - acc: 0.9946 - metric_F1score: 0.99 - ETA: 8s - loss: 0.0308 - acc: 0.9950 - metric_F1score: 0.99 - ETA: 8s - loss: 0.0300 - acc: 0.9953 - metric_F1score: 0.99 - ETA: 8s - loss: 0.0318 - acc: 0.9951 - metric_F1score: 0.99 - ETA: 7s - loss: 0.0318 - acc: 0.9949 - metric_F1score: 0.99 - ETA: 7s - loss: 0.0312 - acc: 0.9952 - metric_F1score: 0.99 - ETA: 7s - loss: 0.0347 - acc: 0.9938 - metric_F1score: 0.99 - ETA: 7s - loss: 0.0343 - acc: 0.9941 - metric_F1score: 0.99 - ETA: 6s - loss: 0.0342 - acc: 0.9940 - metric_F1score: 0.99 - ETA: 6s - loss: 0.0336 - acc: 0.9943 - metric_F1score: 0.99 - ETA: 6s - loss: 0.0349 - acc: 0.9942 - metric_F1score: 0.99 - ETA: 5s - loss: 0.0341 - acc: 0.9945 - metric_F1score: 0.99 - ETA: 5s - loss: 0.0333 - acc: 0.9947 - metric_F1score: 0.99 - ETA: 5s - loss: 0.0339 - acc: 0.9940 - metric_F1score: 0.99 - ETA: 5s - loss: 0.0342 - acc: 0.9939 - metric_F1score: 0.99 - ETA: 4s - loss: 0.0338 - acc: 0.9941 - metric_F1score: 0.99 - ETA: 4s - loss: 0.0351 - acc: 0.9941 - metric_F1score: 0.99 - ETA: 4s - loss: 0.0348 - acc: 0.9943 - metric_F1score: 0.99 - ETA: 3s - loss: 0.0344 - acc: 0.9945 - metric_F1score: 0.99 - ETA: 3s - loss: 0.0340 - acc: 0.9946 - metric_F1score: 0.99 - ETA: 3s - loss: 0.0337 - acc: 0.9948 - metric_F1score: 0.99 - ETA: 3s - loss: 0.0346 - acc: 0.9947 - metric_F1score: 0.99 - ETA: 2s - loss: 0.0351 - acc: 0.9944 - metric_F1score: 0.99 - ETA: 2s - loss: 0.0348 - acc: 0.9946 - metric_F1score: 0.99 - ETA: 2s - loss: 0.0362 - acc: 0.9945 - metric_F1score: 0.99 - ETA: 2s - loss: 0.0370 - acc: 0.9940 - metric_F1score: 0.99 - ETA: 1s - loss: 0.0367 - acc: 0.9942 - metric_F1score: 0.99 - ETA: 1s - loss: 0.0370 - acc: 0.9941 - metric_F1score: 0.99 - ETA: 1s - loss: 0.0367 - acc: 0.9943 - metric_F1score: 0.99 - ETA: 0s - loss: 0.0366 - acc: 0.9942 - metric_F1score: 0.99 - ETA: 0s - loss: 0.0362 - acc: 0.9944 - metric_F1score: 0.99 - ETA: 0s - loss: 0.0372 - acc: 0.9941 - metric_F1score: 0.99 - ETA: 0s - loss: 0.0367 - acc: 0.9943 - metric_F1score: 0.99 - 13s 2ms/step - loss: 0.0367 - acc: 0.9943 - metric_F1score: 0.9943\n",
      "Epoch 10/10\n",
      "5812/5812 [==============================] - ETA: 13s - loss: 0.0246 - acc: 1.0000 - metric_F1score: 1.000 - ETA: 13s - loss: 0.0426 - acc: 0.9961 - metric_F1score: 0.996 - ETA: 12s - loss: 0.0410 - acc: 0.9948 - metric_F1score: 0.994 - ETA: 12s - loss: 0.0354 - acc: 0.9961 - metric_F1score: 0.996 - ETA: 11s - loss: 0.0328 - acc: 0.9969 - metric_F1score: 0.996 - ETA: 11s - loss: 0.0297 - acc: 0.9974 - metric_F1score: 0.997 - ETA: 11s - loss: 0.0273 - acc: 0.9978 - metric_F1score: 0.997 - ETA: 10s - loss: 0.0258 - acc: 0.9980 - metric_F1score: 0.998 - ETA: 10s - loss: 0.0282 - acc: 0.9974 - metric_F1score: 0.997 - ETA: 10s - loss: 0.0306 - acc: 0.9969 - metric_F1score: 0.996 - ETA: 9s - loss: 0.0327 - acc: 0.9964 - metric_F1score: 0.996 - ETA: 9s - loss: 0.0313 - acc: 0.9967 - metric_F1score: 0.99 - ETA: 9s - loss: 0.0300 - acc: 0.9970 - metric_F1score: 0.99 - ETA: 9s - loss: 0.0293 - acc: 0.9972 - metric_F1score: 0.99 - ETA: 8s - loss: 0.0284 - acc: 0.9974 - metric_F1score: 0.99 - ETA: 8s - loss: 0.0280 - acc: 0.9976 - metric_F1score: 0.99 - ETA: 8s - loss: 0.0282 - acc: 0.9968 - metric_F1score: 0.99 - ETA: 7s - loss: 0.0276 - acc: 0.9970 - metric_F1score: 0.99 - ETA: 7s - loss: 0.0269 - acc: 0.9971 - metric_F1score: 0.99 - ETA: 7s - loss: 0.0264 - acc: 0.9973 - metric_F1score: 0.99 - ETA: 7s - loss: 0.0288 - acc: 0.9967 - metric_F1score: 0.99 - ETA: 6s - loss: 0.0283 - acc: 0.9968 - metric_F1score: 0.99 - ETA: 6s - loss: 0.0304 - acc: 0.9963 - metric_F1score: 0.99 - ETA: 6s - loss: 0.0326 - acc: 0.9954 - metric_F1score: 0.99 - ETA: 5s - loss: 0.0329 - acc: 0.9953 - metric_F1score: 0.99 - ETA: 5s - loss: 0.0329 - acc: 0.9952 - metric_F1score: 0.99 - ETA: 5s - loss: 0.0324 - acc: 0.9954 - metric_F1score: 0.99 - ETA: 5s - loss: 0.0320 - acc: 0.9953 - metric_F1score: 0.99 - ETA: 4s - loss: 0.0316 - acc: 0.9954 - metric_F1score: 0.99 - ETA: 4s - loss: 0.0310 - acc: 0.9956 - metric_F1score: 0.99 - ETA: 4s - loss: 0.0313 - acc: 0.9955 - metric_F1score: 0.99 - ETA: 4s - loss: 0.0315 - acc: 0.9954 - metric_F1score: 0.99 - ETA: 3s - loss: 0.0311 - acc: 0.9955 - metric_F1score: 0.99 - ETA: 3s - loss: 0.0313 - acc: 0.9954 - metric_F1score: 0.99 - ETA: 3s - loss: 0.0308 - acc: 0.9955 - metric_F1score: 0.99 - ETA: 2s - loss: 0.0306 - acc: 0.9957 - metric_F1score: 0.99 - ETA: 2s - loss: 0.0304 - acc: 0.9958 - metric_F1score: 0.99 - ETA: 2s - loss: 0.0300 - acc: 0.9959 - metric_F1score: 0.99 - ETA: 2s - loss: 0.0297 - acc: 0.9960 - metric_F1score: 0.99 - ETA: 1s - loss: 0.0294 - acc: 0.9961 - metric_F1score: 0.99 - ETA: 1s - loss: 0.0292 - acc: 0.9962 - metric_F1score: 0.99 - ETA: 1s - loss: 0.0311 - acc: 0.9957 - metric_F1score: 0.99 - ETA: 0s - loss: 0.0313 - acc: 0.9955 - metric_F1score: 0.99 - ETA: 0s - loss: 0.0309 - acc: 0.9956 - metric_F1score: 0.99 - ETA: 0s - loss: 0.0307 - acc: 0.9957 - metric_F1score: 0.99 - 14s 2ms/step - loss: 0.0315 - acc: 0.9954 - metric_F1score: 0.9954\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fbd4114a58>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "def metric_F1score(y_true,y_pred):    \n",
    "    TP=tf.reduce_sum(y_true*tf.round(y_pred))\n",
    "    TN=tf.reduce_sum((1-y_true)*(1-tf.round(y_pred)))\n",
    "    FP=tf.reduce_sum((1-y_true)*tf.round(y_pred))\n",
    "    FN=tf.reduce_sum(y_true*(1-tf.round(y_pred)))\n",
    "    precision=TP/(TP+FP)\n",
    "    recall=TP/(TP+FN)\n",
    "    F1score=2*precision*recall/(precision+recall)\n",
    "    return F1score\n",
    "\n",
    "label = train['label'].astype(int)\n",
    "\n",
    "train_X, val_X, train_Y, val_Y = train_test_split(traintitle, label, shuffle=True, test_size=0.2,\n",
    "                                                    random_state=2019)\n",
    "train_Y = to_categorical(train_Y)\n",
    "\n",
    "model.fit(train_X,\n",
    "          train_Y,\n",
    "          batch_size=128,\n",
    "          epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6118140168738982\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "pred_val = model.predict(val_X)\n",
    "print(f1_score(val_Y, np.argmax(pred_val, axis=1), average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_text(sentence):\n",
    "    tokens = list(jieba.cut(sentence))\n",
    "    #tokens = [token for token in tokens if token not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "model_word2vec = gensim.models.Word2Vec(min_count=1, window=5,  size=256, workers=4,batch_words=1000)\n",
    "model_word2vec.build_vocab(all_doc, progress_per=2000)\n",
    "model_word2vec.train(all_doc, total_examples=model_word2vec.corpus_count, \n",
    "                        epochs=5, compute_loss=True, report_delay=60*10,\n",
    "                        callbacks=[EpochSaver('./final')])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
